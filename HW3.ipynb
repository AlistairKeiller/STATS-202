{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: 'STATS 202 Homework 3'\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISLP import load_data\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.display import Markdown\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "## Problem 1.a\n",
    "**iv.**: Train RSS will steadly decrease, as the model becomes more flexable and will be able to fit the data better.\n",
    "## Problem 1.b\n",
    "**ii.**: Test RSS will decrease as the flexability lets it get closer to the real function $Y_0$, then eventually start overfitting on the training data and therfore having an increased test RSS.\n",
    "## Problem 1.c\n",
    "**iii.**: Variance will steadly increase as the model becomes more flexable and varies to the data better\n",
    "## Problem 1.d\n",
    "**iv.**: squared bias will steadly decrease as the model fits the data better\n",
    "## Problem 1.e\n",
    "**v.**: Irreducible error will remain constant as it is independent of the model.\n",
    "# Problem 2\n",
    "## Problem 2.a\n",
    "**iii.**: Train RSS will steadly increase as the model gets more punished for flexability.\n",
    "## Problem 2.b\n",
    "**ii.**: Test RSS decrease as the increased penalty term prevents overfitting, while it eventually restricts the model from representing $Y_0$, therfore increasing test RSS.\n",
    "## Problem 2.c\n",
    "**iv.**: Variance will steadly decrease as the model is penalized for varying to fit the data\n",
    "## Problem 2.d\n",
    "**iii.**: Squared bias will steadly increase as the penalty term causes the model to be less specific and therfore more biased.s\n",
    "## Problem 2.e\n",
    "**v.**: Irreducable error is independent of the model so will be constant.\n",
    "# Problem 3\n",
    "## Problem 3.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "College = load_data(\"College\")\n",
    "College[\"Private\"] = College[\"Private\"] == \"Yes\"\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    College.drop(\"Apps\", axis=1), College[\"Apps\"], random_state=42\n",
    ")\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The score is: 0.8606501781209516"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(\n",
    "    \"The score is: \"\n",
    "    + str(LinearRegression().fit(X_train, y_train).score(X_test, y_test))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The score is: 0.8626496724638395"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(\n",
    "    \"The score is: \"\n",
    "    + str(\n",
    "        RidgeCV(alphas=np.arange(1, 100))\n",
    "        .fit(scaled_X_train, y_train)\n",
    "        .score(scaled_X_test, y_test)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The score is: 0.8610062021214084"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(\n",
    "    \"The score is: \"\n",
    "    + str(\n",
    "        LassoCV(alphas=np.arange(1, 100))\n",
    "        .fit(scaled_X_train, y_train)\n",
    "        .score(scaled_X_test, y_test)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "the number of nonzero coefficents is: 17"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(\n",
    "    \"the number of nonzero coefficents is: \"\n",
    "    + str(\n",
    "        np.sum(\n",
    "            LassoCV(alphas=np.arange(1, 100)).fit(scaled_X_train, y_train).coef_ != 0\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The best M is: 16"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(\n",
    "    make_pipeline(PCA(), LinearRegression()), {\"pca__n_components\": np.arange(1, 17)}\n",
    ").fit(scaled_X_train, y_train)\n",
    "Markdown(\"The best M is: \" + str(grid.best_params_[\"pca__n_components\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The score is: 0.8664792682433866"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(\"The score is: \" + str(grid.score(scaled_X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The best M is: 16"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(PLSRegression(), {\"n_components\": np.arange(1, 17)}).fit(\n",
    "    scaled_X_train, y_train\n",
    ")\n",
    "Markdown(\"The best M is: \" + str(grid.best_params_[\"n_components\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The score is: 0.8606488441076391"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(\"The score is: \" + str(grid.score(scaled_X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3.g\n",
    "\n",
    "There is not a significant differnce between the results for these methods; without fruther investigation and much deeper analisys, I don't even think we can conclude that these errors have a statistically significant difference. We see that the most accurate model is PCR ( with a $\\approx 87\\%$ accuracy ), while the least accurate is the simple linear regression ( with a $\\approx 86\\%$ accuracy ).\n",
    "\n",
    "# Problem 4\n",
    "## Problem 4.a\n",
    "$$\n",
    "\\begin{split}\n",
    "f_1(x)&=\\beta_0+\\beta_1 x+\\beta_2 x^2+\\beta_3 x^3+\\beta_4(x-\\xi)^3_+ \\\\\n",
    "&=\\beta_0+\\beta_1 x+\\beta_2 x^2+\\beta_3 x^3 \\\\\n",
    "a_1&=\\beta_0 \\\\\n",
    "b_1&=\\beta_1 \\\\\n",
    "c_1&=\\beta_2 \\\\\n",
    "d_1&=\\beta_3+\\beta_4\n",
    "\\end{split}\n",
    "$$\n",
    "## Problem 4.b\n",
    "$$\n",
    "\\begin{split}\n",
    "f_2(x)&=\\beta_0+\\beta_1 x+\\beta_2 x^2+\\beta_3 x^3+\\beta_4(x-\\xi)^3_+ \\\\\n",
    "&=\\beta_0-\\beta_4 \\xi^3+x(\\beta_1+3\\beta_4 \\xi^2)+x^2(\\beta_2-3\\beta_4 \\xi)+x^3(\\beta_3+\\beta_4) \\\\\n",
    "a_2&=\\beta_0-\\beta_4 \\xi^3 \\\\\n",
    "b_2&=\\beta_1+3\\beta_4 \\xi^2 \\\\\n",
    "c_2&=\\beta_2-3\\beta_4 \\xi \\\\\n",
    "d_2&=\\beta_3+\\beta_4\n",
    "\\end{split}\n",
    "$$\n",
    "## Problem 4.c\n",
    "$$\n",
    "\\begin{split}\n",
    "f_1(\\xi)&=\\beta_0+\\beta_1 \\xi+\\beta_2 \\xi^2+\\beta_3 \\xi^3 \\\\\n",
    "f_2(\\xi)&=\\beta_0-\\beta_4 \\xi^3+\\beta_1 \\xi+3\\beta_4 \\xi^3+\\beta_2 \\xi^2-3\\beta_4 \\xi^3+\\beta_3 \\xi^3+\\beta_4 \\xi^3 \\\\\n",
    "&=\\beta_0+\\beta_1 \\xi+\\beta_2 \\xi^2+\\beta_3 \\xi^3\n",
    "\\end{split}\n",
    "$$\n",
    "## Problem 4.d\n",
    "$$\n",
    "\\begin{split}\n",
    "f_1'(\\xi)&=\\beta_1+2\\beta_2 \\xi+3\\beta_3 \\xi^2 \\\\\n",
    "f_2'(\\xi)&=\\beta_1+3\\beta_4 \\xi^2+2\\xi(\\beta_2-3\\beta_4 \\xi)+3\\xi^2(\\beta_3+\\beta_4) \\\\\n",
    "&=\\beta_1+2\\beta_2 \\xi+3\\beta_3 \\xi^2\n",
    "\\end{split}\n",
    "$$\n",
    "## Problem 4.e\n",
    "$$\n",
    "\\begin{split}\n",
    "f_1''(\\xi)&=2\\beta_2+6\\beta_3 \\xi \\\\\n",
    "f_2''(\\xi)&=2(\\beta_2-3\\beta_4 \\xi)+6\\xi(\\beta_3+\\beta_4) \\\\\n",
    "&=2\\beta_2+6\\beta_3 \\xi\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Problem 5\n",
    "Use ANOVA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
