{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: 'STATS 202 Homework 2'\n",
        "format:\n",
        "  html:\n",
        "      code-fold: true\n",
        "---"
      ],
      "id": "6fc84bb8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import statsmodels.formula.api as smf\n",
        "import pandas as pd\n",
        "from ISLP import load_data\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.discriminant_analysis import ( \n",
        "    LinearDiscriminantAnalysis,\n",
        "    QuadraticDiscriminantAnalysis\n",
        ")\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import Latex\n",
        "\n",
        "weekly = load_data('Weekly')\n",
        "default = load_data('default')\n",
        "sns.set_theme(style='dark')"
      ],
      "id": "f40a5c6d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Problem 1\n",
        "\n",
        "$$\n",
        "\\begin{split}\n",
        "p(X)&=\\frac{e^{\\beta_0+\\beta_1 X}}{1+e^{\\beta_0+\\beta_1 X}} \\\\\n",
        "\\frac{p(X)}{1-p(X)}&=\\frac{\\frac{e^{\\beta_0+\\beta_1 X}}{1+e^{\\beta_0+\\beta_1 X}}}{1-\\frac{e^{\\beta_0+\\beta_1 X}}{1+e^{\\beta_0+\\beta_1 X}}} \\\\\n",
        "&=\\frac{\\frac{e^{\\beta_0+\\beta_1 X}}{1+e^{\\beta_0+\\beta_1 X}}}{\\frac{1+e^{\\beta_0+\\beta_1 X}}{1+e^{\\beta_0+\\beta_1 X}}-\\frac{e^{\\beta_0+\\beta_1 X}}{1+e^{\\beta_0+\\beta_1 X}}} \\\\\n",
        "&=\\frac{\\frac{e^{\\beta_0+\\beta_1 X}}{1+e^{\\beta_0+\\beta_1 X}}}{\\frac{1+e^{\\beta_0+\\beta_1 X}}{1+e^{\\beta_0+\\beta_1 X}}-\\frac{e^{\\beta_0+\\beta_1 X}}{1+e^{\\beta_0+\\beta_1 X}}} \\\\\n",
        "&=\\frac{\\frac{e^{\\beta_0+\\beta_1 X}}{1+e^{\\beta_0+\\beta_1 X}}}{\\frac{1+e^{\\beta_0+\\beta_1 X}}{1+e^{\\beta_0+\\beta_1 X}}-\\frac{e^{\\beta_0+\\beta_1 X}}{1+e^{\\beta_0+\\beta_1 X}}} \\\\\n",
        "&=\\frac{\\frac{e^{\\beta_0+\\beta_1 X}}{1+e^{\\beta_0+\\beta_1 X}}}{\\frac{1}{1+e^{\\beta_0+\\beta_1 X}}} \\\\\n",
        "&=e^{\\beta_0+\\beta_1 X}\n",
        "\\end{split}\n",
        "$$\n",
        "\n",
        "# Problem 2\n",
        "\n",
        "## Problem 2.a\n",
        "\n",
        "On average, $\\frac{1}{10}$ of the observations will be used to make the predictions.\n",
        "\n",
        "## Problem 2.b\n",
        "\n",
        "On average, $\\frac{1}{100}$ of the observations will be used to make the predictions.\n",
        "\n",
        "## Problem 2.c\n",
        "\n",
        "On average, $10^{-100}$ of the observations will be used to be used to make the predictions.\n",
        "\n",
        "## Problem 2.d\n",
        "\n",
        "As the number of features increase, fewer of the larger set will be used for inference, which will make the model seem relatively 'dumber' as it sees a very local pictures and never really 'understanding' a larger picture, therefore also causing really high variance and overfitting.\n",
        "\n",
        "## Problem 2.e\n",
        "\n",
        "$$\n",
        "\\begin{split}\n",
        "s^{p}&=10^{-1} \\\\\n",
        "p\\ln s&=-\\ln 10 \\\\\n",
        "\\ln s&=-p^{-1}\\ln 10 \\\\\n",
        "s&=10^{-p^{-1}}\n",
        "\\end{split}\n",
        "$$\n",
        "\n",
        "### p=1\n",
        "\n",
        "$$\n",
        "s=10^{-1}=0.1\n",
        "$$\n",
        "\n",
        "### p=2\n",
        "\n",
        "$$\n",
        "s=10^{-0.5}\\approx .32\n",
        "$$\n",
        "\n",
        "### p=100\n",
        "\n",
        "$$\n",
        "s=10^{-.01}\\approx 0.98\n",
        "$$\n",
        "\n",
        "# Problem 3\n",
        "\n",
        "## Problem 3.a\n",
        "\n",
        "$$\n",
        "Y=\\sigma\\left(\\hat{\\beta}_0+\\hat{\\beta}_1 X_1+\\hat{\\beta}_2 X_2\\right)=\\sigma\\left(-6+40\\cdot .05+1\\cdot 3.5\\right)=\\sigma(-0.5)\\approx .377\n",
        "$$\n",
        "\n",
        "## Problem 3.b\n",
        "\n",
        "$$\n",
        "\\begin{split}\n",
        "0.5&=\\sigma\\left(\\hat{\\beta}_0+\\hat{\\beta}_1 X_1+\\hat{\\beta}_2 X_2\\right)=\\sigma\\left(-6+0.05h+3.5\\right) \\\\\n",
        "0.5&=\\sigma\\left(0.05h-2.5\\right)\n",
        "h\\approx 50\n",
        "\\end{split}\n",
        "$$\n",
        "\n",
        "# Problem 4\n",
        "\n",
        "We would prefer the regression, because the $K=1$ KNN will have a $0\\%$ error on the training data ( the NN of any data point in the training data set will just be itself ), which means that it had a $36\\%$ error on the testing data. Scince the $36\\%$ test error for KNN is more than the $30\\%$ error on the linear regression, we would prefer the regression to classify new observations.\n",
        "\n",
        "# Problem 5\n",
        "\n",
        "## Problem 5.a\n"
      ],
      "id": "a92b6d1f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | warning: false\n",
        "sns.pairplot(weekly, hue='Direction', diag_kws={'multiple': 'stack'})"
      ],
      "id": "39ce2b8f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From looking at the graphs, we can see that Today is clustered by Direction and there is a correlation between Volume and year.\n",
        "\n",
        "## Problem 5.b\n"
      ],
      "id": "281b46a9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "weekly_binary = weekly.assign(\n",
        "    Direction=(weekly['Direction'] == 'Up').astype(int)\n",
        ")\n",
        "model = smf.logit(\n",
        "    'Direction ~ Volume + Lag1 + Lag2 + Lag3 + Lag4 + Lag5',\n",
        "    data=weekly_binary\n",
        ").fit(disp=False)\n",
        "model.summary()"
      ],
      "id": "b84215a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lag2 is the only statistically significant correlation.\n",
        "\n",
        "## Problem 5.c\n"
      ],
      "id": "53b02567"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "prediction = model.predict(\n",
        "    weekly_binary[['Volume', 'Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5']]\n",
        ").round()\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    weekly_binary['Direction'],\n",
        "    prediction\n",
        ")\n",
        "plt.show()"
      ],
      "id": "f70a87ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the model is very hesitant to guess 0, so it has a very low recall, \n",
        "\n",
        "## Problem 5.d\n"
      ],
      "id": "f3dc72d8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "weekly_training = weekly[weekly['Year'] <= 2008]\n",
        "weekly_training_binary = weekly_training.assign(\n",
        "    Direction=(weekly_training['Direction'] == 'Up').astype(int)\n",
        ")\n",
        "weekly_testing = weekly[weekly['Year'] >= 2009]\n",
        "weekly_testing_binary = weekly_testing.assign(\n",
        "    Direction=(weekly_testing['Direction'] == 'Up').astype(int)\n",
        ")\n",
        "model = smf.logit(\n",
        "    'Direction ~ Lag2',\n",
        "    data=weekly_training_binary\n",
        ").fit(disp=False)\n",
        "prediction = model.predict(weekly_testing_binary[['Lag2']]).round()\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    weekly_testing_binary['Direction'],\n",
        "    prediction\n",
        ")\n",
        "plt.show()"
      ],
      "id": "8992d396",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Probelm 5.e\n"
      ],
      "id": "c71e6c59"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = LinearDiscriminantAnalysis().fit(\n",
        "    weekly_training_binary[['Lag2']],\n",
        "    weekly_training_binary['Direction']\n",
        ")\n",
        "prediction = model.predict(weekly_testing_binary[['Lag2']]).round()\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    weekly_testing_binary['Direction'],\n",
        "    prediction\n",
        ")\n",
        "plt.show()"
      ],
      "id": "5e1eee2e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem 5.f\n"
      ],
      "id": "2a24ad34"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = QuadraticDiscriminantAnalysis().fit(\n",
        "    weekly_training_binary[['Lag2']],\n",
        "    weekly_training_binary['Direction']\n",
        ")\n",
        "prediction = model.predict(weekly_testing_binary[['Lag2']]).round()\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    weekly_testing_binary['Direction'],\n",
        "    prediction\n",
        ")\n",
        "plt.show()"
      ],
      "id": "3b593537",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem 5.g\n"
      ],
      "id": "6a424dd5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = KNeighborsClassifier(n_neighbors=1).fit(\n",
        "    weekly_training_binary[['Lag2']],\n",
        "    weekly_training_binary['Direction']\n",
        ")\n",
        "prediction = model.predict(weekly_testing_binary[['Lag2']]).round()\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    weekly_testing_binary['Direction'],\n",
        "    prediction\n",
        ")\n",
        "plt.show()"
      ],
      "id": "8741b46e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Probem 5.h\n"
      ],
      "id": "b345f5c1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = GaussianNB().fit(\n",
        "    weekly_training_binary[['Lag2']],\n",
        "    weekly_training_binary['Direction']\n",
        ")\n",
        "prediction = model.predict(weekly_testing_binary[['Lag2']]).round()\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    weekly_testing_binary['Direction'],\n",
        "    prediction\n",
        ")\n",
        "plt.show()"
      ],
      "id": "1544b944",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Problem 6\n",
        "\n",
        "## Problem 6.a\n",
        "\n",
        "Each bootstrap observation has a $\\frac{1}{n}$ chance of being equal to the $j$th element of the original sample, so it has a $1-\\frac{1}{n}=\\frac{n-1}{n}$ chance of not being the $j$th observation.\n",
        "\n",
        "## Problem 6.b\n",
        "\n",
        "Every bootstrap observation is sampled identically, so it is also $\\frac{n-1}{n}$\n",
        "\n",
        "## Problem 6.c\n",
        "\n",
        "Each bootstrap observation has a $1-\\frac{1}{n}$ probability of not being the $j$th observation, so the chance that every one of $n$ bootsrap observations in a bootstrap sample of size $n$ is not the $j$th observation is $\\left(1-\\frac{1}{n}\\right)^n$.\n",
        "\n",
        "## Problem 6.d\n",
        "\n",
        "$\\left(1-\\frac{1}{n}\\right)^n=\\left(1-\\frac{1}{5}\\right)^5\\approx 0.33$\n",
        "\n",
        "## Problem 6.e\n",
        "\n",
        "$\\left(1-\\frac{1}{n}\\right)^n=\\left(1-\\frac{1}{100}\\right)^{100}\\approx 0.37$\n",
        "\n",
        "## Problem 6.f\n",
        "\n",
        "$\\left(1-\\frac{1}{n}\\right)^n=\\left(1-\\frac{1}{10000}\\right)^{10000}\\approx 0.37$\n",
        "\n",
        "## Problem 6.g\n"
      ],
      "id": "ecdb7df4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x = np.arange(1, 10000)\n",
        "sns.lineplot((1-1/x)**x)\n",
        "plt.show()"
      ],
      "id": "6ec6d932",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$\\left(1-\\frac{1}{n}\\right)^n$ increases and asymptotes to $e^{-1}$.\n",
        "\n",
        "## Python 6.h\n"
      ],
      "id": "2c5f7510"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rng = np.random.default_rng(10)\n",
        "store = np.empty(10000)\n",
        "for i in range(10000):\n",
        "    store[i] = np.sum(rng.choice(100, replace=True) == 4) > 0\n",
        "np.mean(store)"
      ],
      "id": "77967e45",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np.random.seed(10)\n",
        "np.mean(np.random.randint(1, 100, 10000) == 4)"
      ],
      "id": "4f0cf066",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These are both very different from the estimate of $\\left(1-\\frac{1}{100}\\right)^{100}=.37$; the python ones are significantly lower and the R is is significantly higher.\n",
        "\n",
        "# Problem 7\n",
        "## Probblem 7.a\n"
      ],
      "id": "6a20945f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "default_binary = default.assign(\n",
        "    default=(default['default'] == 'Yes').astype(int),\n",
        "    student=(default['student'] == 'Yes').astype(int)\n",
        ")\n",
        "model = smf.logit(\n",
        "    'default ~ income + balance',\n",
        "    data=default_binary\n",
        ").fit(disp=False)\n",
        "model.summary()"
      ],
      "id": "a3c1d94d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem 7.b\n"
      ],
      "id": "62095244"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "default_binary_train, default_binary_test = train_test_split(\n",
        "    default_binary,\n",
        "    test_size=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "model = smf.logit(\n",
        "    'default ~ income + balance',\n",
        "    data=default_binary_train\n",
        ").fit(disp=False)\n",
        "prediction = model.predict(\n",
        "    default_binary_test[['income', 'balance']]\n",
        ").round()\n",
        "error = (\n",
        "    sum(prediction != default_binary_test['default'])\n",
        "    / len(default_binary_test['default'])\n",
        ")"
      ],
      "id": "5e9013d3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The error is `{python} error`\n",
        "\n",
        "## Problem 7.c\n"
      ],
      "id": "dd82fd7f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "splits = [0.25, 0.5, 0.75]\n",
        "errors = []\n",
        "for split in splits:\n",
        "    default_binary_train, default_binary_test = train_test_split(\n",
        "        default_binary,\n",
        "        test_size=split,\n",
        "        random_state=42\n",
        "    )\n",
        "    model = smf.logit(\n",
        "        'default ~ income + balance',\n",
        "        data=default_binary_train\n",
        "    ).fit(disp=False)\n",
        "    prediction = model.predict(\n",
        "        default_binary_test[['income', 'balance']]\n",
        "    ).round()\n",
        "    error = (\n",
        "        sum(prediction != (default_binary_test['default'])\n",
        "        / len(default_binary_test['default'])\n",
        "    )\n",
        "    )\n",
        "    errors.append(error)\n",
        "Latex(pd.DataFrame({\n",
        "    'Training Split': splits,\n",
        "    'Error': errors\n",
        "}).to_latex())"
      ],
      "id": "87addfcd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From these there seems to be a almost parabolic motion centered somewhere around $0.5$, such that increasing or decreasing the training split will derease performance on the testing data.\n",
        "\n",
        "## Problem 7.d\n"
      ],
      "id": "6d0aa6a0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "default_binary_train, default_binary_test = train_test_split(\n",
        "    default_binary,\n",
        "    test_size=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "model = smf.logit(\n",
        "    'default ~ student + income + balance',\n",
        "    data=default_binary_train\n",
        ").fit(disp=False)\n",
        "prediction = model.predict(\n",
        "    default_binary_test[['student', 'income', 'balance']]\n",
        ").round()\n",
        "error = (\n",
        "    sum(prediction != default_binary_test['default'])\n",
        "    / len(default_binary_test['default'])\n",
        ")"
      ],
      "id": "d9367f6f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The error is `{python} error`, which is an improvment over the version without student, which means that student is providing more information to the model rather than just providing a point of overfitting for the training."
      ],
      "id": "fb14756c"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}